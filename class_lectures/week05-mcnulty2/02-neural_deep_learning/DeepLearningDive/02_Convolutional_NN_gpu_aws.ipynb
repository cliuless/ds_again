{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2><center><font color='black'>   Taking a Deep-Learning Dive with Keras </font></center></h2>\n",
    "\n",
    "open_placeholder_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import keras.utils.np_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D, ZeroPadding1D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 487s 3us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    " \n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_test=to_categorical(y_test)\n",
    "y_train=to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Let's work with VGG16 model again\n",
    "\n",
    "Lets import the model this time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, None, None, 64)1792        input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, None, None, 64)36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, None, None, 64)0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, None, None, 12873856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, None, None, 128147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, None, None, 1280           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, None, None, 256295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, None, None, 256590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, None, None, 256590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, None, None, 2560           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, None, None, 5121180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, None, None, 5122359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, None, None, 5122359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, None, None, 5120           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, None, None, 5122359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, None, None, 5122359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, None, None, 5122359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, None, None, 5120           block5_conv3[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 14714688\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "image_input (InputLayer)         (None, 32, 32, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_3 (Model)                  multiple              14714688    image_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 512)           0           model_3[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "fc1 (Dense)                      (None, 4096)          2101248     flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "fc2 (Dense)                      (None, 4096)          16781312    fc1[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "predictions (Dense)              (None, 10)            40970       fc2[0][0]                        \n",
      "====================================================================================================\n",
      "Total params: 33638218\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "model_vgg16_conv = VGG16(weights=None, include_top=False)\n",
    "model_vgg16_conv.summary()\n",
    "\n",
    "#Create your own input format \n",
    "input = Input(shape=(32,32,3),name = 'image_input')  # our input shape: (3,32,32)\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = model_vgg16_conv(input)\n",
    "\n",
    "#Add the fully-connected layers \n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(input=input, output=x)  # Using the Functional API\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "my_model.compile(optimizer=sgd, loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 2.3043 - acc: 0.1001Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "50000/50000 [==============================] - 235s - loss: 2.3043 - acc: 0.1000 - val_loss: 2.3043 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 193s - loss: 2.3043 - acc: 0.0986 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 193s - loss: 2.3044 - acc: 0.0997 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 193s - loss: 2.3045 - acc: 0.1000 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 193s - loss: 2.3043 - acc: 0.0984 - val_loss: 2.3043 - val_acc: 0.1000\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 193s - loss: 2.3044 - acc: 0.0987 - val_loss: 2.3044 - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f041f165490>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_a=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "# lets look at our results while we are at it\n",
    "cb_b=keras.callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "\n",
    "\n",
    "my_model.fit(X_train, y_train,\n",
    "          batch_size=128, nb_epoch=10, verbose=1,\n",
    "          validation_data=(X_test, y_test),callbacks=[cb_a,cb_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our Training has flat-lined!  \n",
    "Let's try again: **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code-Along! \n",
    "\n",
    "Let's repeat the MNIST training by leveraging [Transfer Learning](http://cs231n.github.io/transfer-learning/)\n",
    "\n",
    "1) Reinstantiate your VGG16 model: this time set weights='imagenet'    \n",
    "2) Freeze all previous layers\n",
    "\n",
    "hint: \n",
    "```\n",
    "for layer in my_model.layers:    \n",
    "    print(layer.trainable)\n",
    "        \n",
    "```\n",
    "3) We'll want to rescale our image features to be between 0 & 1:   \n",
    "\n",
    "hint: see Kera's [ImageDataGenerator Function](https://keras.io/preprocessing/image/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Setting up a Deep Learning AWS GPU Instance\n",
    "\n",
    "- Use the **fantastic** EC2 Image that a former student of ours\n",
    "- It has all sorts of goodies preconfigured for your Deep Learning joy\n",
    "- You can find his repo [here](https://github.com/Miej/GoDeeper)\n",
    "- Now follow along with me as we venture Beyond the Wall!\n",
    "- **Caution**: This will cost $.  If you don't have your AWS credits, be wary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching the Instance\n",
    "1. Proceed to the AWS EC2 Console\n",
    "2. Click \"Launch Instance\"\n",
    "3. Click Community AMIs\n",
    "4. Search for \"3e22685e\" (make sure you're in the US West (N California) zone or it won't show up)\n",
    "5. Click Select\n",
    "6. Select the g2.2xlarge instance and click \"Next: Configure Instance Details\"\n",
    "7. Click thru the defaults until Step 5: Tag Instance, give it a name \"GPU\"\n",
    "8. Click thru to Step 6: Configure Security Group.  In the rules, select All TCP and Address \"My IP\", \"Review and Launch\"!\n",
    "9. Choose the keypair you should already have and let 'er rip!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "1. Log onto your server via:\n",
    "  - `ssh -i <your_keypair.pem> icarus@<your_public_ip>`\n",
    "  - Password: `changetheworld`\n",
    "2. Log out\n",
    "3. In EC2 Console, reboot your instance (for init scripts to run)\n",
    "4. Log back in again (#1 above) and let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
