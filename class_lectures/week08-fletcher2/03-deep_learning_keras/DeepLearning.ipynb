{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning for NLP: An Application-based Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Basics\n",
    "from __future__ import print_function, division\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# sklearn\n",
    "\n",
    "# keras\n",
    "np.random.seed(13)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Reshape, Activation, SimpleRNN, GRU, LSTM, Convolution1D, MaxPooling1D, Merge, Dropout\n",
    "from IPython.display import SVG\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer, base_filter\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intro to `Keras` with Artificial Neural Networks (ANNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What is `Keras`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- What is `Keras`?\n",
    "  - A fantastic **wrapper**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - Around what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - **TensorFlow** and/or **Theano**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - And what do those do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - **Deep Learning**!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Learning Reminder\n",
    "- Deep Learning is going to take over the world\n",
    "<img  src=\"img/landscape-1431110160-terminator.jpg\" style='height:200px'/>\n",
    "- Allegedly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Learning Reminder \n",
    "- Deep Learning = Fancy ANNs (Artificial Neural Networks)\n",
    "- \"**Deep**\" $\\rightarrow$ Many Hidden Layers\n",
    "- Fancy $\\rightarrow$ Complex Network structures that capture more information from data\n",
    "<div>\n",
    "<table align=\"center\"><tr><td><img  src=\"img/neural_net.jpeg\" style=\"float: left; width: 100%; margin-right: 1%; margin-bottom: 0.5em;\"/></td><td><img  src=\"img/rnn.png\" style=\"float: left; width: 100%; height: 300px; margin-right: 1%; margin-bottom: 0.5em;\"/></td></tr><tr><td style=\"text-align: center\">Simple 2-layer ANN</td><td style=\"text-align: center\">Deep Recurrent Neural Network (RNN)</td></tr></table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Learning Don't Stress\n",
    "- You got this!\n",
    "- The concepts are all the same:\n",
    "  - Nodes feedforward to their successors and backpropagate to update weights to their predecessors\n",
    "  - Weights matrices represent transitions between nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Learning Don't Stress\n",
    "1. Take the input\n",
    "2. Run it thru the network\n",
    "3. Compute the Error/Cost\n",
    "4. Backpropagate to update weights via gradient of cost function\n",
    "\n",
    "We could do a whole course on this!  But today, we'll focus on applications :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Keras` Setup\n",
    "- `pip install keras`\n",
    "- In `.bashrc`/`.bash_profile`: `export KERAS_BACKEND=theano`\n",
    "  - You can run TensorFlow instead if you want\n",
    "- For visualizing networks:\n",
    "  - `pip install pydot-ng`\n",
    "  - `brew install graphviz`\n",
    "  - `pip install pydot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Keras`: Using the GPU\n",
    "- Deep Learning requires tons of matrix computations\n",
    "- GPUs can do this really fast in parallel (many cores!)\n",
    "- Optional: Set up with your GPU (if you can!)\n",
    "  - Install [CUDA](http://docs.nvidia.com/cuda/index.html#axzz4Pa5zY8Qi) \n",
    "  - In `.bashrc`/`.bash_profile`: `export THEANO_FLAGS=device=gpu,floatX=float32`\n",
    "- Don't worry, you can just use AWS's big toys!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Keras` Models\n",
    "- The core objects in `Keras` are `Models` and `Layers`\n",
    "- `Models` set up the container for your network\n",
    "- `Layers` fill in the architecture (connections, unit types, activation functions, etc)\n",
    "- The 2 options for `Models`:\n",
    "  - `Sequential`: The basic one we'll focus on\n",
    "  - Function API: Specify complex uncommon models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Sequential Model\n",
    "- Allow you to stack all sorts of layers in your network\n",
    "- Canvas on which you paint your beautiful network!\n",
    "- We'll focus on these only today\n",
    "- Let's take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Keras Sequential model \n",
    "model = Sequential()\n",
    "\n",
    "# Specify the network architecture\n",
    "# Here we add layers to our model, we'll come back to that in a bit\n",
    "model.add(Dense(output_dim=64, input_dim=100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Viewing the Network\n",
    "- `Keras` let's you view your network architecture!\n",
    "- Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"377pt\" viewBox=\"0.00 0.00 314.56 377.00\" width=\"315pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 373)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-373 310.556,-373 310.556,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4752953424 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4752953424</title>\n",
       "<polygon fill=\"none\" points=\"0,-324.5 0,-368.5 306.556,-368.5 306.556,-324.5 0,-324.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-342.3\">dense_input_8: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"167.238,-324.5 167.238,-368.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.073\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167.238,-346.5 222.907,-346.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.073\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222.907,-324.5 222.907,-368.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.731\" y=\"-353.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"222.907,-346.5 306.556,-346.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.731\" y=\"-331.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 4752953744 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4752953744</title>\n",
       "<polygon fill=\"none\" points=\"27.9932,-243.5 27.9932,-287.5 278.562,-287.5 278.562,-243.5 27.9932,-243.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-261.3\">dense_14: Dense</text>\n",
       "<polyline fill=\"none\" points=\"139.245,-243.5 139.245,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.08\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"139.245,-265.5 194.914,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.08\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"194.914,-243.5 194.914,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.738\" y=\"-272.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"194.914,-265.5 278.562,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.738\" y=\"-250.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 4752953424&#45;&gt;4752953744 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4752953424-&gt;4752953744</title>\n",
       "<path d=\"M153.278,-324.329C153.278,-316.183 153.278,-306.699 153.278,-297.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.778,-297.729 153.278,-287.729 149.778,-297.729 156.778,-297.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4752953872 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4752953872</title>\n",
       "<polygon fill=\"none\" points=\"8.41504,-162.5 8.41504,-206.5 298.141,-206.5 298.141,-162.5 8.41504,-162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"87.1191\" y=\"-180.3\">activation_11: Activation</text>\n",
       "<polyline fill=\"none\" points=\"165.823,-162.5 165.823,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193.658\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"165.823,-184.5 221.492,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193.658\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"221.492,-162.5 221.492,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.816\" y=\"-191.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"221.492,-184.5 298.141,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.816\" y=\"-169.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 4752953744&#45;&gt;4752953872 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4752953744-&gt;4752953872</title>\n",
       "<path d=\"M153.278,-243.329C153.278,-235.183 153.278,-225.699 153.278,-216.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.778,-216.729 153.278,-206.729 149.778,-216.729 156.778,-216.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4755312400 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4755312400</title>\n",
       "<polygon fill=\"none\" points=\"31.4932,-81.5 31.4932,-125.5 275.062,-125.5 275.062,-81.5 31.4932,-81.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"87.1191\" y=\"-99.3\">dense_15: Dense</text>\n",
       "<polyline fill=\"none\" points=\"142.745,-81.5 142.745,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.58\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"142.745,-103.5 198.414,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.58\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"198.414,-81.5 198.414,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.738\" y=\"-110.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"198.414,-103.5 275.062,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.738\" y=\"-88.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 4752953872&#45;&gt;4755312400 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4752953872-&gt;4755312400</title>\n",
       "<path d=\"M153.278,-162.329C153.278,-154.183 153.278,-144.699 153.278,-135.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.778,-135.729 153.278,-125.729 149.778,-135.729 156.778,-135.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4754643344 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4754643344</title>\n",
       "<polygon fill=\"none\" points=\"8.15869,-0.5 8.15869,-44.5 298.397,-44.5 298.397,-0.5 8.15869,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"87.1191\" y=\"-18.3\">activation_12: Activation</text>\n",
       "<polyline fill=\"none\" points=\"166.08,-0.5 166.08,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193.914\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"166.08,-22.5 221.749,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193.914\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"221.749,-0.5 221.749,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.073\" y=\"-29.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"221.749,-22.5 298.397,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.073\" y=\"-7.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 4755312400&#45;&gt;4754643344 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>4755312400-&gt;4754643344</title>\n",
       "<path d=\"M153.278,-81.3294C153.278,-73.1826 153.278,-63.6991 153.278,-54.7971\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.778,-54.729 153.278,-44.729 149.778,-54.729 156.778,-54.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the network graphically\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So pretty! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Compiling the Network\n",
    "- Sets up training parameters before training\n",
    "- e.g.: Cost (Loss) function, Optimization method, Scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Training the Network\n",
    "- Like `sklearn`, call `fit` (usually) on `numpy` arrays!\n",
    "- ***Epoch***: 1 Full pass through the training set\n",
    "  - Remember, training with Gradient Descent (or similar) we likely take many passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 0s - loss: 2.3406 - acc: 0.0950     \n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 0s - loss: 2.3232 - acc: 0.1100     \n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 0s - loss: 2.3123 - acc: 0.1150     \n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 0s - loss: 2.3016 - acc: 0.1300     \n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 0s - loss: 2.2971 - acc: 0.1250     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10b41c590>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some fake data\n",
    "from keras.utils.np_utils import to_categorical\n",
    "X_train = np.random.random((200, 100))\n",
    "y_train = np.random.randint(0, 10, 200)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "# Fit the model \n",
    "model.fit(X_train, y_train, nb_epoch=5, batch_size=32)\n",
    "\n",
    "# Fit in batches \n",
    "# model.train_on_batch(X_batch, Y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Evaluating and Making Predictions\n",
    "- Like `sklearn`, we have nice predict and evaluation functions!\n",
    "- Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/200 [===>..........................] - ETA: 0s\n",
      " [2.3699144649505617, 0.059999999999999998]\n",
      " 32/200 [===>..........................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "X_test = np.random.random((200, 100))\n",
    "y_test = np.random.randint(0, 10, 200)\n",
    "y_test = to_categorical(y_test)\n",
    "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('\\n', loss_and_metrics)\n",
    "\n",
    "# Make Predictions\n",
    "classes = model.predict_classes(X_test, batch_size=32)\n",
    "proba = model.predict_proba(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The Functional API\n",
    "- Let's you specify more complicated models\n",
    "- Not our focus today, `Sequential` is plenty!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Keras` Layers\n",
    "- Layers are where the real action's at\n",
    "- This is where you \"architect\" your network\n",
    "- Different architectures solve different problems well!\n",
    "- Layers define:\n",
    "  - Nodes (Network Units, can be complex themselves)\n",
    "  - Connections\n",
    "  - Properties on Units and Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dense Layers\n",
    "- Simplest kind of layer, `Dense`\n",
    "- Familiar from standard ANN\n",
    "- Fully connected between inputs and outputs\n",
    "- This is the usual gal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 2 ways to specify layers:\n",
    "# Model Constructor or add() method\n",
    "# These are the same model: \n",
    "model1 = Sequential([\n",
    "    Dense(32, input_dim=784),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(32, input_dim=784))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "# Same model \n",
    "#SVG(model_to_dot(model1, show_shapes=True).create(prog='dot', format='svg'))\n",
    "# SVG(model_to_dot(model2, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Activation Layers\n",
    "- Specify the **activation function** for a layer\n",
    "- How the inputs are combined with weights in the layer\n",
    "- Options: `softmax`, `sigmoid`, `relu`, `tanh`, more...\n",
    "- Use `softmax` for multiclass outputs!  For K classes:\n",
    "$P(y=j|x) = frac{e^{x^Tw_j}}{\\sum\\limits_{k=1}^K e^{x^Tw_k}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Merge Layers\n",
    "- Merge multiple `Sequential` models into a single layer\n",
    "- A number of options for merging outputs: `concat`, `sum`, `ave`, etc\n",
    "- Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"215pt\" viewBox=\"0.00 0.00 625.56 215.00\" width=\"626pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 211)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-211 621.562,-211 621.562,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4759551184 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4759551184</title>\n",
       "<polygon fill=\"none\" points=\"0,-162.5 0,-206.5 299.562,-206.5 299.562,-162.5 0,-162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.1226\" y=\"-180.3\">sequential_13: Sequential</text>\n",
       "<polyline fill=\"none\" points=\"160.245,-162.5 160.245,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.08\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"160.245,-184.5 215.914,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.08\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"215.914,-162.5 215.914,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.738\" y=\"-191.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"215.914,-184.5 299.562,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.738\" y=\"-169.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 4759551888 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4759551888</title>\n",
       "<polygon fill=\"none\" points=\"149.929,-81.5 149.929,-125.5 467.634,-125.5 467.634,-81.5 149.929,-81.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"204.136\" y=\"-99.3\">merge_2: Merge</text>\n",
       "<polyline fill=\"none\" points=\"258.344,-81.5 258.344,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286.178\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"258.344,-103.5 314.013,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286.178\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"314.013,-81.5 314.013,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390.823\" y=\"-110.3\">[(None, 32), (None, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"314.013,-103.5 467.634,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390.337\" y=\"-88.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 4759551184&#45;&gt;4759551888 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4759551184-&gt;4759551888</title>\n",
       "<path d=\"M192.39,-162.329C212.343,-152.416 236.278,-140.523 257.242,-130.108\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"258.932,-133.176 266.33,-125.592 255.818,-126.907 258.932,-133.176\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4759551248 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4759551248</title>\n",
       "<polygon fill=\"none\" points=\"318,-162.5 318,-206.5 617.562,-206.5 617.562,-162.5 318,-162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398.123\" y=\"-180.3\">sequential_14: Sequential</text>\n",
       "<polyline fill=\"none\" points=\"478.245,-162.5 478.245,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.08\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"478.245,-184.5 533.914,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.08\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"533.914,-162.5 533.914,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"575.738\" y=\"-191.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"533.914,-184.5 617.562,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"575.738\" y=\"-169.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 4759551248&#45;&gt;4759551888 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4759551248-&gt;4759551888</title>\n",
       "<path d=\"M425.172,-162.329C405.22,-152.416 381.284,-140.523 360.321,-130.108\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"361.745,-126.907 351.232,-125.592 358.63,-133.176 361.745,-126.907\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4759752336 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4759752336</title>\n",
       "<polygon fill=\"none\" points=\"186.997,-0.5 186.997,-44.5 430.566,-44.5 430.566,-0.5 186.997,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242.623\" y=\"-18.3\">dense_24: Dense</text>\n",
       "<polyline fill=\"none\" points=\"298.249,-0.5 298.249,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326.083\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"298.249,-22.5 353.917,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326.083\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"353.917,-0.5 353.917,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"392.242\" y=\"-29.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"353.917,-22.5 430.566,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"392.242\" y=\"-7.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 4759551888&#45;&gt;4759752336 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4759551888-&gt;4759752336</title>\n",
       "<path d=\"M308.781,-81.3294C308.781,-73.1826 308.781,-63.6991 308.781,-54.7971\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"312.281,-54.729 308.781,-44.729 305.281,-54.729 312.281,-54.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the 2 models\n",
    "left_branch = Sequential()\n",
    "left_branch.add(Dense(32, input_dim=784))\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(Dense(32, input_dim=784))\n",
    "\n",
    "# Merge\n",
    "merged = Merge([left_branch, right_branch], mode='concat')\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add(merged)\n",
    "final_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Take a look \n",
    "SVG(model_to_dot(final_model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Advanced Layers\n",
    "- Bunch of additional layer options\n",
    "- For state of the art performance on NLP, Image Proc, etc\n",
    "- e.g.:\n",
    "  - Convolutional Layers\n",
    "  - Pooling Layers\n",
    "  - Recurrent Layers\n",
    "  - Embedding Layers\n",
    "  - and more!\n",
    "- We'll briefly touch on a few as we see them in examples\n",
    "- Remember, today is about applications!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras: A Simple Example ANN\n",
    "- Let's try a simple example with document classification\n",
    "- We'll use only Dense and Activation Layers\n",
    "- Plus 1 more!\n",
    "- **Dropout**:\n",
    "  - Controls for **Overfitting** $\\rightarrow$ **Regularization**\n",
    "  - Randomly zeros out certain inputs in the layer\n",
    "- We'll use the famous Reuters Document Classification set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.5503 - acc: 0.2120     \n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.7617 - acc: 0.2168     \n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.8244 - acc: 0.2081     \n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.8648 - acc: 0.2104     \n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - 1s - loss: 4.7534 - acc: 0.2144     \n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.7971 - acc: 0.2135     \n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.7839 - acc: 0.2140     \n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.7223 - acc: 0.2150     \n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.8765 - acc: 0.2116     \n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.7866 - acc: 0.2093     \n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.8972 - acc: 0.2201     \n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 2s - loss: 5.1136 - acc: 0.2169     \n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.8033 - acc: 0.2220     \n",
      "Epoch 14/20\n",
      "8982/8982 [==============================] - 1s - loss: 4.7584 - acc: 0.2132     \n",
      "Epoch 15/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.7733 - acc: 0.2130     \n",
      "Epoch 16/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.8552 - acc: 0.2077     \n",
      "Epoch 17/20\n",
      "8982/8982 [==============================] - 2s - loss: 4.7658 - acc: 0.2133     \n",
      "Epoch 18/20\n",
      "8982/8982 [==============================] - 1s - loss: 4.8289 - acc: 0.2131     \n",
      "Epoch 19/20\n",
      "8982/8982 [==============================] - 1s - loss: 4.6811 - acc: 0.2140     \n",
      "Epoch 20/20\n",
      "8982/8982 [==============================] - 1s - loss: 4.6931 - acc: 0.2157     \n",
      "2208/2246 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Set the max number of words to keep, 2000 most frequent \n",
    "max_features = 2000\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(nb_words=max_features)\n",
    "maxlen = 10\n",
    "# Data is stored in sentences, pad any that are shorter than 10 words with zeros\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, input_dim=10, init='uniform'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, init='uniform'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(46, init='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Momentum: gradient descent moves faster if gradient keeps pointing in the same direction\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          nb_epoch=20,\n",
    "          batch_size=16)\n",
    "score = model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Mmm...not a great job!  Although with 46 classes it's okay, but I think we can do better.  We'll return!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A (slightly) more complex example: Skipgrams!\n",
    "- Back to your old favorite\n",
    "- Let's see if we can implement Skipgrams in `Keras`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.gutenberg.org/files/11/11-0.txt\n",
      "180224/173595 [===============================] - 1s    \n"
     ]
    }
   ],
   "source": [
    "# Load in Corpus using Keras utility\n",
    "# We'll use Alice in Wonderland :)\n",
    "path = get_file('carrol-alice.txt', origin=\"http://www.gutenberg.org/files/11/11-0.txt\")\n",
    "corpus = open(path).readlines()[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Keras: Preprocessing Data\n",
    "- `Keras` has some nice text preprocessing features too!\n",
    "- We need to convert into a special format, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[654, 304, 80, 87, 10, 225, 50, 188, 210],\n",
       " [27, 81, 89, 21, 1, 58, 8, 410, 321, 36, 37, 270, 6, 83],\n",
       " [212, 37, 491, 253, 19, 336, 419, 4, 324, 4, 203, 101],\n",
       " [388, 58, 4, 136, 1, 486, 8, 1, 180, 128, 493, 485],\n",
       " [39, 27, 81, 23, 437, 36, 580, 128, 353],\n",
       " [460, 80, 87, 10, 191],\n",
       " [533, 188, 210],\n",
       " [310, 151, 641, 351, 655, 81, 422, 9],\n",
       " [473, 151, 564, 574],\n",
       " [492, 255, 467, 308, 472],\n",
       " [558, 474, 402, 624, 386],\n",
       " [616, 8, 27, 180, 128, 81, 80, 87, 10, 225, 9],\n",
       " [80, 87, 10, 191],\n",
       " [1, 390, 245, 476, 483, 478],\n",
       " [600, 16, 11, 1, 31, 520],\n",
       " [14, 5, 396, 3, 55, 17, 265, 8, 257, 50, 15, 142, 30, 44],\n",
       " [560, 6, 8, 656, 66, 3, 46, 241, 23, 471, 2, 20, 623, 70, 44],\n",
       " [100, 15, 142, 5, 470, 18, 4, 20, 37, 202, 23, 360, 651],\n",
       " [4, 121, 52, 89, 1, 58, 8, 7, 100, 12, 48, 14, 405, 202, 101],\n",
       " [32, 2, 5, 208, 10, 15, 605, 182, 25, 94, 25, 2, 77, 21, 44],\n",
       " [333, 364, 236, 15, 403, 17, 216, 6, 389, 237, 1, 455],\n",
       " [8, 322, 7, 399, 244, 41, 34, 254, 1, 259, 8, 227, 24, 59],\n",
       " [490, 1, 344, 72, 57, 7, 175, 31, 39, 328, 415, 425],\n",
       " [201, 50, 15, 9],\n",
       " [35, 5, 66, 32, 17, 251, 10, 13, 365, 102, 14, 28, 4, 625],\n",
       " [17, 67, 33, 8, 1, 56, 3, 235, 1, 31, 54, 3, 530, 143, 131, 9],\n",
       " [145, 131, 16, 88, 34, 159, 12, 72, 2, 48, 4, 112, 500, 367],\n",
       " [643, 3, 15, 13, 2, 562, 3, 183, 385, 36, 27, 18, 36, 1, 379],\n",
       " [4, 26, 134, 394, 341, 18, 72, 1, 31, 354, 176, 7, 141],\n",
       " [33, 8, 350, 232, 196, 6, 82, 36, 4, 6, 114, 378, 30, 9],\n",
       " [14, 311, 3, 15, 163, 21, 4, 426, 204, 15, 182, 13, 2, 194],\n",
       " [74, 62, 184, 7, 31, 39, 69, 7, 232, 196, 23, 7, 141],\n",
       " [3, 436, 33, 8, 4, 6, 607, 39, 337, 2, 431, 204, 1, 267],\n",
       " [150, 4, 6, 330, 5, 125, 10, 40, 3, 38, 4, 502, 11, 7, 138],\n",
       " [31, 110, 136, 1, 469, 9],\n",
       " [10, 172, 91, 11, 63, 14, 150, 4, 74, 241, 208, 149],\n",
       " [10, 1, 569, 2, 5, 3, 55, 33, 99, 9],\n",
       " [1, 31, 110, 63, 519, 30, 49, 7, 319, 21, 582, 56, 6, 349],\n",
       " [556, 57, 11, 32, 57, 13, 14, 20, 22, 7, 91, 3, 601],\n",
       " [51, 524, 64, 62, 2, 116, 64, 277, 11, 7, 17, 504],\n",
       " [69, 1, 94, 5, 17, 633, 23, 2, 132, 17, 508, 21, 2, 194],\n",
       " [443, 8, 40, 25, 2, 63, 11, 3, 123, 51, 15, 6, 3, 65, 52, 181],\n",
       " [193, 3, 382, 303, 78, 2, 111, 3, 123, 11, 6, 535, 33, 627],\n",
       " [2, 5, 338, 3, 18, 4, 5, 79, 126, 3, 38, 226, 114, 127],\n",
       " [82, 36, 1, 646, 8, 1, 94, 6, 229, 13, 76, 45, 279, 83],\n",
       " [133, 6, 100, 170, 107, 6, 35, 2, 185, 352, 6, 252],\n",
       " [576, 124, 366, 2, 176, 11, 7, 190, 109, 53, 8, 1, 170, 166],\n",
       " [2, 411, 4, 5, 315, 299, 612, 18, 3, 15, 373],\n",
       " [496, 4, 5, 512, 2, 102, 22, 49, 3, 370, 1, 190, 21, 644],\n",
       " [8, 489, 359, 32, 243, 3, 169, 4, 70, 53, 8, 1, 133, 166],\n",
       " [2, 132, 268, 4, 9],\n",
       " [557, 12, 48, 14, 3, 64, 348, 173, 7, 73, 25, 27, 16, 642],\n",
       " [28, 66, 8, 541, 11, 461, 43, 263, 152, 26, 28, 42, 117],\n",
       " [586, 444, 16, 339, 54, 226, 51, 4, 105, 47, 16, 132, 92, 1, 540],\n",
       " [8, 1, 376, 12, 119, 5, 17, 269, 622, 9],\n",
       " [11, 11, 11, 41, 1, 73, 74, 205, 3, 634, 329, 68, 65, 149],\n",
       " [206, 200, 213, 400, 50, 27, 40, 12, 2, 85, 345, 68, 144, 34, 480],\n",
       " [158, 522, 1, 589, 8, 1, 189, 283, 42, 38, 13, 41, 34, 618],\n",
       " [514, 200, 11, 16, 28, 12, 21, 19, 38, 14, 20, 479, 302],\n",
       " [90, 8, 27, 130, 10, 15, 457, 10, 1, 509, 6, 440, 234],\n",
       " [5, 22, 7, 17, 161, 549, 21, 565, 92, 15, 459, 25, 498],\n",
       " [5, 37, 53, 3, 413, 3, 15, 157, 4, 5, 161, 361, 3, 54, 4, 112, 9],\n",
       " [240, 554, 228, 51, 1, 96, 423, 18, 114, 16, 65, 52, 381],\n",
       " [23, 146, 213, 165, 3, 12, 14, 20, 37, 377, 52, 355, 5, 101],\n",
       " [146, 69, 18, 48, 76, 45, 239, 542, 198, 3, 54, 9],\n",
       " [256, 2, 154, 99, 68, 65, 47, 16, 88, 73, 96, 61, 44],\n",
       " [189, 43, 532, 195, 433, 3, 205, 33, 215, 1, 224, 13, 503, 83],\n",
       " [174, 409, 577, 1, 523, 16, 28, 12, 2, 5, 153, 581],\n",
       " [35, 5, 37, 53, 568, 27, 40, 25, 4, 187, 518, 36, 26, 44],\n",
       " [96, 318, 240, 18, 16, 88, 183, 3, 171, 115, 52, 1, 369, 8, 1, 566],\n",
       " [89, 19, 222, 481, 295, 89, 27, 276, 445, 23, 563, 12, 59],\n",
       " [2, 111, 3, 325, 25, 2, 301, 404, 320, 25, 300, 428],\n",
       " [61, 1, 211, 46, 19, 28, 19, 77, 297, 4, 121, 52, 447],\n",
       " [314, 29, 636, 573, 28, 42, 21, 590, 37, 195, 74, 46, 177],\n",
       " [171, 534, 16, 88, 38, 4, 462, 24, 158, 104],\n",
       " [11, 11, 11, 35, 5, 66, 515, 3, 46, 32, 14, 156, 392],\n",
       " [432, 99, 441, 406, 42, 17, 67, 3, 575, 16, 463, 28, 104],\n",
       " [93, 5, 1, 272, 68, 465, 152, 342, 15, 588, 8, 248, 117],\n",
       " [266, 40, 93, 75, 131, 16, 238, 19, 45, 11, 107, 39, 42, 35, 477, 487],\n",
       " [620, 10, 1, 211, 551, 548, 18, 19, 113, 517, 7, 199, 6, 228, 449],\n",
       " [49, 7, 531, 19, 222, 18, 46, 98, 71, 97, 16, 65, 12, 6, 107, 323],\n",
       " [154, 3, 55, 153, 216, 6, 63, 30, 186, 3, 64, 10, 7, 430],\n",
       " [130, 8, 56, 418, 98, 71, 97, 46, 98, 71, 97, 12, 6, 448, 446],\n",
       " [97, 71, 98, 12, 21, 19, 38, 25, 2, 584, 334, 69, 615, 9],\n",
       " [4, 187, 67, 427, 119, 56, 2, 169, 4, 2, 640, 13, 2, 5, 397],\n",
       " [92, 6, 20, 125, 164, 3, 346, 13, 2, 5, 452, 214, 10, 214, 83],\n",
       " [93, 6, 186, 3, 15, 17, 561, 343, 93, 309, 42, 1, 371, 9],\n",
       " [102, 19, 106, 71, 7, 199, 12, 72, 57, 160, 160, 11, 2, 120, 416],\n",
       " [7, 619, 8, 631, 6, 288, 290, 6, 1, 73, 5, 112, 9],\n",
       " [14, 5, 22, 7, 570, 312, 6, 2, 450, 24, 30, 3, 15, 163, 10, 7, 91, 9],\n",
       " [2, 82, 24, 18, 4, 5, 26, 126, 306, 62, 15, 5, 626],\n",
       " [129, 135, 6, 1, 175, 31, 5, 157, 10, 585, 488, 11, 4, 9],\n",
       " [35, 5, 22, 7, 91, 3, 34, 572, 203, 63, 14, 49, 1, 347, 59],\n",
       " [5, 125, 10, 40, 3, 235, 4, 54, 25, 4, 168, 7, 139, 143, 75, 356],\n",
       " [6, 595, 43, 159, 218, 227, 12, 2, 5, 201, 217, 4, 72, 127],\n",
       " [168, 1, 139, 18, 1, 31, 5, 37, 647, 3, 34, 184, 2, 579],\n",
       " [64, 10, 7, 129, 230, 84, 119, 5, 435, 24, 50, 7, 278, 8, 598, 464],\n",
       " [109, 1, 271, 9],\n",
       " [35, 45, 220, 26, 103, 1, 84, 18, 76, 45, 26, 258, 6, 292],\n",
       " [14, 20, 506, 26, 1, 56, 11, 53, 372, 6, 24, 1, 219, 621, 617],\n",
       " [60, 2, 649, 395, 11, 1, 529, 307, 43, 2, 5, 106, 177],\n",
       " [55, 33, 99, 9],\n",
       " [57, 2, 120, 124, 7, 29, 505, 608, 207, 26, 236, 8, 527],\n",
       " [313, 35, 5, 66, 30, 4, 559, 7, 611, 140, 86, 6, 285],\n",
       " [78, 48, 5, 13, 4, 113, 536, 3, 53, 8, 1, 220, 8, 1, 84, 9],\n",
       " [18, 417, 69, 1, 327, 45, 79, 261, 23, 1, 86, 5, 79, 137, 9],\n",
       " [18, 36, 118, 179, 4, 41, 22, 387, 118, 8, 115, 122, 30, 1, 591],\n",
       " [40, 103, 2, 120, 124, 7, 230, 510, 2, 20, 22, 229, 62, 59],\n",
       " [217, 4, 5, 7, 29, 60, 51, 287, 233, 147, 2, 111, 44],\n",
       " [29, 140, 86, 10, 1, 599, 6, 3, 15, 289, 546, 4, 653, 9],\n",
       " [14, 384, 1, 60, 6, 116, 13, 4, 281, 70, 7, 137, 135, 609],\n",
       " [67, 291, 420, 7, 357, 110, 2, 246, 11, 6, 82, 286, 1, 602],\n",
       " [70, 1, 499, 148, 19, 106, 185, 43, 2, 652, 3, 55, 33, 528],\n",
       " [13, 126, 84, 6, 383, 51, 215, 209, 650, 8, 454, 458, 59],\n",
       " [209, 260, 442, 18, 2, 77, 22, 105, 55, 15, 231, 61, 44],\n",
       " [495, 121, 105, 47, 75, 231, 41, 247, 61, 12, 48, 638, 14, 552],\n",
       " [41, 34, 8, 17, 29, 58, 550, 75, 513, 145, 43, 16, 238, 16, 375],\n",
       " [391, 24, 49, 7, 374, 16, 28, 16, 77, 47, 16, 192, 593, 43, 3, 439, 104],\n",
       " [21, 19, 38, 32, 206, 33, 8, 1, 56, 90, 20, 358, 637, 9],\n",
       " [13, 14, 20, 164, 3, 28, 13, 17, 614, 90, 155, 45, 242],\n",
       " [35, 134, 3, 34, 37, 58, 10, 275, 50, 1, 29, 60, 32, 2, 398],\n",
       " [583, 3, 1, 207, 363, 526, 2, 113, 456, 172, 86, 30, 4, 23, 117],\n",
       " [118, 179, 7, 100, 8, 221, 21, 197, 224, 24, 49, 543, 234],\n",
       " [40, 2, 116, 7, 29, 95, 30, 4, 412, 249, 5, 22, 284],\n",
       " [62, 12, 85, 14, 6, 103, 1, 421, 8, 1, 95, 5, 7, 639],\n",
       " [482, 39, 1, 198, 167, 597, 326, 604, 30, 4, 10, 138],\n",
       " [4, 5, 26, 17, 94, 3, 54, 167, 42, 12, 18, 1, 468, 29, 14, 181],\n",
       " [22, 193, 3, 46, 13, 10, 7, 316, 587, 424, 123, 78, 12, 2, 85, 629],\n",
       " [38, 237, 218, 108, 547, 23, 567, 21, 2, 20, 539, 407, 451],\n",
       " [29, 298, 51, 274, 537, 20, 165, 571, 6, 606, 24, 50, 628],\n",
       " [282, 6, 219, 305, 90, 26, 610, 76, 41, 22, 401],\n",
       " [1, 501, 221, 174, 645, 20, 380, 115, 173, 25, 13, 7, 262, 178],\n",
       " [335, 521, 596, 19, 47, 19, 250, 4, 79, 129, 6, 13, 47, 19, 555, 525],\n",
       " [484, 17, 273, 39, 7, 592, 4, 293, 317, 6, 2, 20, 340],\n",
       " [497, 13, 47, 19, 545, 67, 109, 7, 95, 108, 223, 12, 4, 434],\n",
       " [212, 632, 3, 393, 39, 19, 362, 23, 630, 9],\n",
       " [122, 27, 95, 5, 22, 108, 223, 12, 32, 14, 294, 3, 368],\n",
       " [4, 6, 438, 4, 17, 239, 4, 20, 10, 553, 7, 130, 8, 603, 494],\n",
       " [8, 453, 578, 613, 332, 296, 594, 507, 466, 6, 178],\n",
       " [331, 280, 2, 17, 156, 516, 4, 92, 9],\n",
       " [9],\n",
       " [9],\n",
       " [9],\n",
       " [414, 7, 635, 429, 12, 85, 14, 68, 144, 34, 197, 24, 49, 648],\n",
       " [6, 32, 4, 5, 155, 2, 5, 162, 192, 264, 233, 147, 6, 15, 475],\n",
       " [538, 24, 36, 1, 48, 13, 2, 5, 162, 1, 96, 408, 21, 544],\n",
       " [61, 1, 29, 60, 70, 13, 511, 148, 78, 122, 127]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For simplicity, one \"sentence\" per line \n",
    "corpus = [sentence for sentence in corpus if sentence.count(\" \") >= 2]\n",
    "\n",
    "# Tokenize using Keras\n",
    "tokenizer = Tokenizer(filters=base_filter()+\"'\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "# Convert tokenized sentences to sequence format\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "nb_samples = sum(len(s) for s in corpus)\n",
    "\n",
    "# Vocab size\n",
    "V = len(tokenizer.word_index) + 1\n",
    "# Dimension to reduce to\n",
    "dim = 100\n",
    "window_size = 2\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Skipgrams: Generating Input and Output Labels\n",
    "- Now we need to generate our `X_train` and `y_train`\n",
    "- So we can train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate the inputs and outputs for all windows\n",
    "def generate_data(sequences, window_size, V):\n",
    "    maxlen = window_size*2\n",
    "    # For each line (sentence)\n",
    "    for words in sequences:\n",
    "        L = len(words)\n",
    "        # Choose the target word\n",
    "        for index, word in enumerate(words):\n",
    "            # Create the window\n",
    "            s = index-window_size\n",
    "            e = index+window_size+1\n",
    "                    \n",
    "            in_words = []\n",
    "            labels = []\n",
    "            # Create the input/outputs for skipgrams\n",
    "            for i in range(s, e):\n",
    "                if i != index and 0 <= i < L:\n",
    "                    in_words.append([word] )\n",
    "                    labels.append(words[i])\n",
    "\n",
    "            x = np.array(in_words,dtype=np.int32)\n",
    "            y = np_utils.to_categorical(labels, V)\n",
    "            yield (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Skipgrams: Creating the Model\n",
    "- Lastly, we create the (shallow) network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"296pt\" viewBox=\"0.00 0.00 330.89 296.00\" width=\"331pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 292)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-292 326.887,-292 326.887,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4760230736 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4760230736</title>\n",
       "<polygon fill=\"none\" points=\"0,-243.5 0,-287.5 322.887,-287.5 322.887,-243.5 0,-243.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-261.3\">embedding_input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"197.569,-243.5 197.569,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.404\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"197.569,-265.5 253.238,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.404\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"253.238,-243.5 253.238,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.062\" y=\"-272.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"253.238,-265.5 322.887,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.062\" y=\"-250.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 4760580368 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4760580368</title>\n",
       "<polygon fill=\"none\" points=\"2.71387,-162.5 2.71387,-206.5 320.173,-206.5 320.173,-162.5 2.71387,-162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84.7847\" y=\"-180.3\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"166.855,-162.5 166.855,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.69\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"166.855,-184.5 222.524,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.69\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222.524,-162.5 222.524,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.349\" y=\"-191.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"222.524,-184.5 320.173,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.349\" y=\"-169.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 4760230736&#45;&gt;4760580368 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4760230736-&gt;4760580368</title>\n",
       "<path d=\"M161.443,-243.329C161.443,-235.183 161.443,-225.699 161.443,-216.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"164.943,-216.729 161.443,-206.729 157.943,-216.729 164.943,-216.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4760606288 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4760606288</title>\n",
       "<polygon fill=\"none\" points=\"21,-81.5 21,-125.5 301.887,-125.5 301.887,-81.5 21,-81.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84.7847\" y=\"-99.3\">reshape_1: Reshape</text>\n",
       "<polyline fill=\"none\" points=\"148.569,-81.5 148.569,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.404\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"148.569,-103.5 204.238,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.404\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"204.238,-81.5 204.238,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"253.062\" y=\"-110.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"204.238,-103.5 301.887,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"253.062\" y=\"-88.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 4760580368&#45;&gt;4760606288 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4760580368-&gt;4760606288</title>\n",
       "<path d=\"M161.443,-162.329C161.443,-154.183 161.443,-144.699 161.443,-135.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"164.943,-135.729 161.443,-125.729 157.943,-135.729 164.943,-135.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4752850576 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4752850576</title>\n",
       "<polygon fill=\"none\" points=\"36.1587,-0.5 36.1587,-44.5 286.728,-44.5 286.728,-0.5 36.1587,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"91.7847\" y=\"-18.3\">dense_28: Dense</text>\n",
       "<polyline fill=\"none\" points=\"147.411,-0.5 147.411,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.245\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"147.411,-22.5 203.08,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.245\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"203.08,-0.5 203.08,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.904\" y=\"-29.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"203.08,-22.5 286.728,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.904\" y=\"-7.3\">(None, 657)</text>\n",
       "</g>\n",
       "<!-- 4760606288&#45;&gt;4752850576 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4760606288-&gt;4752850576</title>\n",
       "<path d=\"M161.443,-81.3294C161.443,-73.1826 161.443,-63.6991 161.443,-54.7971\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"164.943,-54.729 161.443,-44.729 157.943,-54.729 164.943,-54.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Keras model and view it \n",
    "skipgram = Sequential()\n",
    "skipgram.add(Embedding(input_dim=V, output_dim=dim, init='glorot_uniform', input_length=1))\n",
    "skipgram.add(Reshape((dim, )))\n",
    "skipgram.add(Dense(input_dim=dim, output_dim=V, activation='softmax'))\n",
    "SVG(model_to_dot(skipgram, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Skipgrams: Compiling and Training\n",
    "- Time to compile and train\n",
    "- We use crossentropy, common loss for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nan\n",
      "1 nan\n",
      "2 nan\n",
      "3 nan\n",
      "4 nan\n",
      "5 nan\n",
      "6 nan\n",
      "7 nan\n",
      "8 nan\n",
      "9 nan\n"
     ]
    }
   ],
   "source": [
    "# Compile the Keras Model\n",
    "skipgram.compile(loss='categorical_crossentropy', optimizer=\"adadelta\")\n",
    "\n",
    "# Fit the Skipgrams\n",
    "for iteration in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data(sequences, window_size, V):\n",
    "        loss += skipgram.train_on_batch(x, y)\n",
    "\n",
    "    print(iteration, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Skipgrams: Saving the Vectors\n",
    "- Let's save the vectors to a file\n",
    "- So we can load them into word2vec and test them out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Write the resulting vectors to a text file\n",
    "f = open('vectors.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Skipgrams: Examining the Vectors\n",
    "- Let's load the vectors in to query them with `gensim`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'this\\r', 0.3330727219581604),\n",
       " (u'read', 0.27034682035446167),\n",
       " (u'ought', 0.2681456506252289),\n",
       " (u'please', 0.2609839141368866),\n",
       " (u'there', 0.25028860569000244),\n",
       " (u'taste\\r', 0.2501465976238251),\n",
       " (u'half', 0.24524283409118652),\n",
       " (u'turkey', 0.2368951439857483),\n",
       " (u'could\\r', 0.2360805720090866),\n",
       " (u'shall\\r', 0.23158985376358032)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the vectors into word2vec and see how we did!\n",
    "w2v = Word2Vec.load_word2vec_format('./vectors.txt', binary=False)\n",
    "w2v.most_similar(positive=['white', 'rabbit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "- So far, stuck to simple ANNs (fully connected)\n",
    "- RNNs change the game\n",
    "- How do they do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "- Connections between units form a **directed cycle**\n",
    "- Allows network to retain internal state from past units $\\rightarrow$ **memory**\n",
    "- Allows dynamic temporal behavior\n",
    "- Can use memory to process arbitrary input sequences!\n",
    "- Terrific success in various NLP tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "- How do they do it?\n",
    "- Hidden Units at a time step t are dependent on:\n",
    "  - The previous hidden unit\n",
    "  - The input at time step t\n",
    "<img  src=\"img/rnn3.jpg\" style=\"width:50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "- Drawback of ANNs: Fixed # of inputs and outputs\n",
    "- RNNs can map arbitrary length sequences of each!\n",
    "<img  src=\"img/rnn2.jpeg\" style=\"width:50%\"/>\n",
    "- Don't stress!  Just a different architecture with some nice features!  Same solving concepts apply!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "- One more view!\n",
    "<img  src=\"img/rnn4.png\" style=\"width:50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RNN Example: Text Classification\n",
    "- Let's try an RNN for the same Reuters classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Same data loading as before\n",
    "max_features = 2000\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(\n",
    "    nb_words=max_features)\n",
    "maxlen = 10\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"377pt\" viewBox=\"0.00 0.00 337.89 377.00\" width=\"338pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 373)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-373 333.887,-373 333.887,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4772565136 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4772565136</title>\n",
       "<polygon fill=\"none\" points=\"0,-324.5 0,-368.5 329.887,-368.5 329.887,-324.5 0,-324.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-342.3\">embedding_input_2: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"197.569,-324.5 197.569,-368.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.404\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"197.569,-346.5 253.238,-346.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.404\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"253.238,-324.5 253.238,-368.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291.562\" y=\"-353.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"253.238,-346.5 329.887,-346.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291.562\" y=\"-331.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 4772507536 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4772507536</title>\n",
       "<polygon fill=\"none\" points=\"2.71387,-243.5 2.71387,-287.5 327.173,-287.5 327.173,-243.5 2.71387,-243.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84.7847\" y=\"-261.3\">embedding_2: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"166.855,-243.5 166.855,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.69\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"166.855,-265.5 222.524,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.69\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222.524,-243.5 222.524,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.849\" y=\"-272.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"222.524,-265.5 327.173,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.849\" y=\"-250.3\">(None, 10, 100)</text>\n",
       "</g>\n",
       "<!-- 4772565136&#45;&gt;4772507536 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4772565136-&gt;4772507536</title>\n",
       "<path d=\"M164.943,-324.329C164.943,-316.183 164.943,-306.699 164.943,-297.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"168.443,-297.729 164.943,-287.729 161.443,-297.729 168.443,-297.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4772565072 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4772565072</title>\n",
       "<polygon fill=\"none\" points=\"3.47949,-162.5 3.47949,-206.5 326.407,-206.5 326.407,-162.5 3.47949,-162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84.7847\" y=\"-180.3\">simplernn_1: SimpleRNN</text>\n",
       "<polyline fill=\"none\" points=\"166.09,-162.5 166.09,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193.924\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"166.09,-184.5 221.759,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193.924\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"221.759,-162.5 221.759,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.083\" y=\"-191.3\">(None, 10, 100)</text>\n",
       "<polyline fill=\"none\" points=\"221.759,-184.5 326.407,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.083\" y=\"-169.3\">(None, 20)</text>\n",
       "</g>\n",
       "<!-- 4772507536&#45;&gt;4772565072 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4772507536-&gt;4772565072</title>\n",
       "<path d=\"M164.943,-243.329C164.943,-235.183 164.943,-225.699 164.943,-216.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"168.443,-216.729 164.943,-206.729 161.443,-216.729 168.443,-216.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4772565840 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4772565840</title>\n",
       "<polygon fill=\"none\" points=\"43.1587,-81.5 43.1587,-125.5 286.728,-125.5 286.728,-81.5 43.1587,-81.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-99.3\">dense_29: Dense</text>\n",
       "<polyline fill=\"none\" points=\"154.411,-81.5 154.411,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.245\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"154.411,-103.5 210.08,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.245\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"210.08,-81.5 210.08,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.404\" y=\"-110.3\">(None, 20)</text>\n",
       "<polyline fill=\"none\" points=\"210.08,-103.5 286.728,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.404\" y=\"-88.3\">(None, 46)</text>\n",
       "</g>\n",
       "<!-- 4772565072&#45;&gt;4772565840 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4772565072-&gt;4772565840</title>\n",
       "<path d=\"M164.943,-162.329C164.943,-154.183 164.943,-144.699 164.943,-135.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"168.443,-135.729 164.943,-125.729 161.443,-135.729 168.443,-135.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4777263632 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4777263632</title>\n",
       "<polygon fill=\"none\" points=\"19.8242,-0.5 19.8242,-44.5 310.062,-44.5 310.062,-0.5 19.8242,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-18.3\">activation_22: Activation</text>\n",
       "<polyline fill=\"none\" points=\"177.745,-0.5 177.745,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.58\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"177.745,-22.5 233.414,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.58\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"233.414,-0.5 233.414,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.738\" y=\"-29.3\">(None, 46)</text>\n",
       "<polyline fill=\"none\" points=\"233.414,-22.5 310.062,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.738\" y=\"-7.3\">(None, 46)</text>\n",
       "</g>\n",
       "<!-- 4772565840&#45;&gt;4777263632 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>4772565840-&gt;4777263632</title>\n",
       "<path d=\"M164.943,-81.3294C164.943,-73.1826 164.943,-63.6991 164.943,-54.7971\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"168.443,-54.729 164.943,-44.729 161.443,-54.729 168.443,-54.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "# The Embedding layer allows us to map words into dense vectors as inputs, common first layer\n",
    "model.add(Embedding(input_dim=max_features, output_dim=100, init='glorot_uniform', input_length=maxlen))\n",
    "# This is the most basic kind of RNN!  We're using 20 units, \n",
    "#which somewhat reflects our \"memory\" of past events in a sequence\n",
    "# For the purposes of keras, it's just another type of \"unit\" you can try!\n",
    "model.add(SimpleRNN(20, return_sequences=False))\n",
    "model.add(Dense(46))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 1s - loss: 3.4709 - acc: 0.2403 - val_loss: 2.8493 - val_acc: 0.3624\n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 0s - loss: 2.5354 - acc: 0.3712 - val_loss: 2.3653 - val_acc: 0.4443\n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 1s - loss: 2.2912 - acc: 0.4319 - val_loss: 2.2724 - val_acc: 0.4533\n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 0s - loss: 2.1866 - acc: 0.4497 - val_loss: 2.2144 - val_acc: 0.4176\n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - 1s - loss: 2.1223 - acc: 0.4614 - val_loss: 2.1498 - val_acc: 0.4559\n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 0s - loss: 2.0703 - acc: 0.4715 - val_loss: 2.1286 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 1s - loss: 2.0302 - acc: 0.4780 - val_loss: 2.1132 - val_acc: 0.4635\n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.9952 - acc: 0.4791 - val_loss: 2.1387 - val_acc: 0.4386\n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.9631 - acc: 0.4899 - val_loss: 2.0834 - val_acc: 0.4604\n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.9314 - acc: 0.4962 - val_loss: 2.0749 - val_acc: 0.4657\n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.9015 - acc: 0.5028 - val_loss: 2.0730 - val_acc: 0.4657\n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.8734 - acc: 0.5090 - val_loss: 2.0710 - val_acc: 0.4697\n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.8486 - acc: 0.5177 - val_loss: 2.0698 - val_acc: 0.4706\n",
      "Epoch 14/20\n",
      "8982/8982 [==============================] - 0s - loss: 1.8198 - acc: 0.5275 - val_loss: 2.1712 - val_acc: 0.4586\n",
      "Epoch 15/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.7968 - acc: 0.5286 - val_loss: 2.0839 - val_acc: 0.4617\n",
      "Epoch 16/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.7706 - acc: 0.5386 - val_loss: 2.0751 - val_acc: 0.4702\n",
      "Epoch 17/20\n",
      "8982/8982 [==============================] - 0s - loss: 1.7427 - acc: 0.5456 - val_loss: 2.1219 - val_acc: 0.4666\n",
      "Epoch 18/20\n",
      "8982/8982 [==============================] - 0s - loss: 1.7211 - acc: 0.5550 - val_loss: 2.0772 - val_acc: 0.4599\n",
      "Epoch 19/20\n",
      "8982/8982 [==============================] - 0s - loss: 1.6949 - acc: 0.5602 - val_loss: 2.0750 - val_acc: 0.4688\n",
      "Epoch 20/20\n",
      "8982/8982 [==============================] - 0s - loss: 1.6761 - acc: 0.5656 - val_loss: 2.0867 - val_acc: 0.4755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11bc0bd90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=256, nb_epoch=nb_epoch, \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**WHOA!** Over 100% improvement on ANN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Long Short-Term Memory (LSTM) Networks\n",
    "- LSTM are a special kind of RNN (invented in 1997)\n",
    "- State of the art for many sequence to sequence mapping and text generation tasks\n",
    "- Adds an explicit \"memory\" unit\n",
    "- Augment RNNs with a few additional **Gate Units**\n",
    "  - Gate Units control how long/if events will stay in memory\n",
    "  - **Input Gate**: If its value is such, it causes items to be stored in memory\n",
    "  - **Forget Gate**: If its value is such, it causes items to be removed from memory\n",
    "  - **Output Gate**: If its value is such, it causes the hidden unit to feed forward (output) in the network\n",
    "- Here's what it looks like:\n",
    "<img  src=\"img/LSTM.png\" style=\"height:300px\"/>\n",
    "- We won't go much further in theory, just know this is state of the art (ish)\n",
    "  - And you can do it!  Watch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LSTM Example: Sentiment Analysis\n",
    "- Here is some code to train sentiment analysis on IMDB reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_full.pkl\n",
      "65560576/65552540 [==============================] - 745s   \n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (25000, 80)\n",
      "X_test shape: (25000, 80)\n",
      "Build model...\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 720s - loss: 0.5275 - acc: 0.7343 - val_loss: 0.3998 - val_acc: 0.8257\n",
      "Epoch 2/15\n",
      "23168/25000 [==========================>...] - ETA: 43s - loss: 0.3814 - acc: 0.8358"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "max_features = 20000\n",
    "maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "# Load data (Keras utility)\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "# Pad Short sentences\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "# Build our model!\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, dropout=0.2))\n",
    "# Here's the LSTM magic!\n",
    "model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "# Sigmoid for binary classification\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n",
    "          validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks (CNN)\n",
    "- You've seen CNNs a little\n",
    "- They'll be discussed more next week with images\n",
    "- Had great success with images\n",
    "- But, they do some nice things with NLP too!..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CNN Example: Sentiment Analysis Revisited\n",
    "- Here's the same Sentiment task with a CNN + LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Embedding\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "embedding_size = 128\n",
    "\n",
    "# Convolution\n",
    "filter_length = 5\n",
    "nb_filter = 64\n",
    "pool_length = 4\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Training\n",
    "batch_size = 30\n",
    "nb_epoch = 2\n",
    "\n",
    "'''\n",
    "Note:\n",
    "batch_size is highly sensitive.\n",
    "Only 2 epochs are needed as the dataset is very small.\n",
    "'''\n",
    "\n",
    "# Load data\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "# Pad sentences\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "# Convolution!\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "model.add(MaxPooling1D(pool_length=pool_length))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bidirectional Recurrent Neural Networks (RNN)\n",
    "- Bidirectionall RNNs simply connect in both directions\n",
    "- Thus, output can be dependent on both future and past inputs\n",
    "- Good for context around a word, for instance\n",
    "  - e.g. Named Entity Recognition, is this a \"person\" token?\n",
    "<img  src=\"brnn.jpg\" style=\"width:70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do you feel about all this sentiment?\n",
    "- One more time on the sentiment, now with a BRNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "# Bidirectional LSTM!!!\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=4,\n",
    "          validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Onward to AWS!\n",
    "- Now that you saw how long those CPUs can take...\n",
    "- Let's go to GPUs!\n",
    "- That means AWS..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setting up a Deep Learning AWS GPU Instance\n",
    "- We're going to use the **fantastic** EC2 Image that a former student of mine set up\n",
    "- It has all sorts of goodies preconfigured for your Deep Learning joy\n",
    "- You can find his repo [here](https://github.com/Miej/GoDeeper)\n",
    "- Now follow along with me as we venture Beyond the Wall!\n",
    "- **Caution**: This will cost $.  If you don't have your AWS credits, be wary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Launching the Instance\n",
    "1. Proceed to the AWS EC2 Console\n",
    "2. Click \"Launch Instance\"\n",
    "3. Click Community AMIs\n",
    "4. Search for \"3e22685e\" (make sure you're in the US West (N California) zone or it won't show up)\n",
    "5. Click Select\n",
    "6. Select the g2.2xlarge instance and click \"Next: Configure Instance Details\"\n",
    "7. Click thru the defaults until Step 5: Tag Instance, give it a name \"GPU\"\n",
    "8. Click thru to Step 6: Configure Security Group.  In the rules, select All TCP and Address \"My IP\", \"Review and Launch\"!\n",
    "9. Choose the keypair you should already have and let 'er rip!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Configuration\n",
    "1. Log onto your server via:\n",
    "  - `ssh -i <your_keypair.pem> icarus@<your_public_ip>`\n",
    "  - Password: `changetheworld`\n",
    "2. Log out\n",
    "3. In EC2 Console, reboot your instance (for init scripts to run)\n",
    "4. Log back in again (#1 above) and let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Start a Jupyter Notebook (on your server)\n",
    "- You know how to do this!:\n",
    "  - `jupyter notebook`\n",
    "- If you want it to be open to the internet, you'll need to follow these instructions:\n",
    "  - [Running Jupyter Notebook Server in AWS](http://jupyter-notebook.readthedocs.io/en/latest/public_server.html)\n",
    "- In your local browser, browse to:\n",
    "  - `https://<your_public_ip>:8888`\n",
    "  - Note, you'll probably have to `pip install gensim` on the server\n",
    "- And let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## AWS LSTM + CNN Example: Sentiment 1 more time!\n",
    "- Let's marvel at how blazing fast the same example runs on your GPU instance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Embedding\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "embedding_size = 128\n",
    "\n",
    "# Convolution\n",
    "filter_length = 5\n",
    "nb_filter = 64\n",
    "pool_length = 4\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Training\n",
    "batch_size = 30\n",
    "nb_epoch = 2\n",
    "\n",
    "'''\n",
    "Note:\n",
    "batch_size is highly sensitive.\n",
    "Only 2 epochs are needed as the dataset is very small.\n",
    "'''\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "model.add(MaxPooling1D(pool_length=pool_length))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LSTM Example: Text Generation\n",
    "- Finally, a different example!\n",
    "- We're going to do **Text Generation** with **LSTM**\n",
    "- We'll watch our model start spitting out words of Nils's favorite philosopher in real time!\n",
    "  - ps, it's Friedrich Nietzsche\n",
    "- As we go through epoch's, the ability to generate Nietzcheian sentences will get better and better!\n",
    "- Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=1)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Additional Excitement: `seq2seq`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `seq2seq` Example: Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `seq2seq` Use Case: Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other Successful Deep Learning Applications\n",
    "- Machine Translation\n",
    "- Named Entity Recognition\n",
    "- Image Processing (next week!)\n",
    "- Image + Video Captioning\n",
    "- Chatbots\n",
    "- Text Generation\n",
    "- Question Answering"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "livereveal": {
   "height": "100%",
   "margin": 0,
   "maxScale": 1,
   "minScale": 1,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky",
   "transition": "zoom",
   "width": "100%"
  },
  "toc": {
   "nav_menu": {
    "height": "369px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "457px",
    "left": "0px",
    "right": "968px",
    "top": "130px",
    "width": "214px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
