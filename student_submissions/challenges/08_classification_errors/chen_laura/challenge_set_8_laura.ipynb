{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic:        Challenge Set #8  \n",
    "Subject:      Sub  \n",
    "Date:         02/5/2018  \n",
    "Name:         Laura Chen  \n",
    "Worked with:  N/A  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Error Metric Challenges\n",
    "**Settings: Where applicable, use test_size=0.30, random_state=4444. This will permit comparison of results across users.\n",
    "\n",
    "These reference the Classification Challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1\n",
    "For the house representatives data set, calculate the accuracy, precision, recall and f1 scores of each classifier you built (on the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting up the data\n",
    "df=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data')\n",
    "\n",
    "df.replace('n',0,inplace=True)\n",
    "df.replace('y',1,inplace=True)\n",
    "df.replace('?',np.nan,inplace=True)\n",
    "df.fillna(round(df.mean()),inplace=True)\n",
    "y=df.republican\n",
    "X=df.drop('republican',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=4444)\n",
    "\n",
    "#Setting up the models again\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=14)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_y_pred = knn.predict(X_test)\n",
    "\n",
    "reg=LogisticRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "reg_y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN results\n",
      "Accuracy: 0.931\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   democrat       0.93      0.96      0.94        79\n",
      " republican       0.94      0.88      0.91        52\n",
      "\n",
      "avg / total       0.93      0.93      0.93       131\n",
      "\n",
      "Logistic Regression results\n",
      "Accuracy: 0.954\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   democrat       0.94      0.99      0.96        79\n",
      " republican       0.98      0.90      0.94        52\n",
      "\n",
      "avg / total       0.96      0.95      0.95       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This function returns a vector with precision, recall, fscore, and support\n",
    "print('KNN results')\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, knn.predict(X_test)))\n",
    "print(classification_report(y_test, knn.predict(X_test)))\n",
    "\n",
    "print('Logistic Regression results')\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, reg.predict(X_test)))\n",
    "print(classification_report(y_test, reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2  \n",
    "For each, draw the ROC curve and calculate the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3  \n",
    "Calculate the same metrics you did in challenge 1, but this time in a cross validation scheme with the cross_val_score function (like in Challenge 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurachen/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4  \n",
    "For your movie classifiers, calculate the precision and recall for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_df=pd.read_csv('2013_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=movie_df['Rating']\n",
    "X=movie_df.drop(['Rating','Title','Director','ReleaseDate'],axis=1)\n",
    "X.fillna(0,inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression results\n",
      "\n",
      "Accuracy: 0.636\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         PG       1.00      0.33      0.50         6\n",
      "      PG-13       0.55      0.92      0.69        13\n",
      "          R       0.78      0.50      0.61        14\n",
      "\n",
      "avg / total       0.73      0.64      0.62        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Linear Regression results\\n')\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, lr.predict(X_test)))\n",
    "print(classification_report(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5  \n",
    "Draw the ROC curve (and calculate AUC) for the logistic regression classifier from challenge 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
